{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bb3bf8-bc1a-44b8-bb10-15ec0f48c393",
   "metadata": {},
   "source": [
    "# Fulmine LABS Eyball\n",
    "\r",
    "## Overview\n",
    "This Python code implements a class wrapper around an Anomaly Detection model which can be used to visually check if an image is anomalous or not. The supported architecture for this model is 'Siamese Network'.\n",
    "In order to perform reduce false negatives the code compares the image against a jury of randomly selected known good images of configurable size 'jury_size'.\n",
    "If the number of jurors who vote that the image is simlar to the chosen known good image is below a configurable 'threshold' then the code returns a verdict of 'Anomalous', otherwise it returns a verdict of 'Normal'.\n",
    "If an image path is not specified but screen coordinates are, these will be used instead, enabling direct integration with automated visual checking scripts.\n",
    "\n",
    "One goal is to use this class as part of automating visual checking of a medical image (PACS) production pipeline, although it could theoretically visually check any type of image on which the model has been trained.\n",
    "\n",
    "It also has the capability of describing the images, using GPT-4 Turbo Vision, if an OpenAI key is supplied in the 'Eyball-OpenAI_key.txt' file.\n",
    "\n",
    "## Initialize the Eyball class\n",
    "\n",
    "predictor = ModelPredictor(siamese_model_path, known_good_images_folder, Eyball_key, threshold, jury_size)\n",
    "\n",
    "## Example calls\n",
    "\n",
    "role = \"You are a radiology PACS test engineer, analyzing PACS or test process related image anomalies\"\n",
    "\n",
    "image_description_directive = \"If the image is obviously not a medical image, state *** ANOMALOUS ***. If it is a typical medical image as acquired by an imaging modality with no additions or enhancements, state *** NORMAL ***. Otherwise, if it is a medical image but it also clearly has textual overlays or annotations or digital or image processing artifacts that could have been added by the PACS image viewer technology, describe those features and append *** ANOMALOUS ***.\"\n",
    "\n",
    "verdict = predictor.predict_siamese(test_image_path)\n",
    "\n",
    "actual_description = predictor.describe_image(test_image_path, None, role, image_description_directive)\r\n",
    "\r\n",
    "## Author\r\n",
    "Duncan Henderson\r\n",
    "Fulmine Labs LLC\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91377e08-daaa-42a1-bfb4-07e422ffb5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image, ImageGrab\n",
    "import logging\n",
    "import random\n",
    "import base64\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81e10613-ac38-499e-92d4-43b77337f087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "known_good_images_folder = r\"D:\\training_images\\test\\valid\"\n",
    "siamese_model_path = r'models\\lung_ct_siamese_network_weights_043024.h5'\n",
    "\n",
    "api_key_file='Eyball-OpenAI_key.txt'\n",
    "\n",
    "jury_size=12\n",
    "threshold = 0.5\n",
    "\n",
    "# LLM prompts\n",
    "role = \"You are a radiology PACS test engineer, analyzing PACS or test process related image anomalies\"\n",
    "image_description_directive = \"If the image is obviously not a medical image, state *** ANOMALOUS ***. If it is a typical medical image as acquired by an imaging modality with no additions or enhancements, state *** NORMAL ***. Otherwise, if it is a medical image but it also clearly has textual overlays or annotations or digital or image processing artifacts that could have been added by the PACS image viewer technology, describe those features and append *** ANOMALOUS ***.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "667993ce-d3c3-423e-b555-312b0f543291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelPredictor:\n",
    "\n",
    "#     def __init__(self, siamese_model_path, known_good_images_folder, api_key_file='Eyball-OpenAI_key.txt', threshold=0.5, jury_size=12):\n",
    "#         self.siamese_model_path = siamese_model_path\n",
    "#         self.known_good_images_folder = known_good_images_folder\n",
    "#         self.api_key = self.load_api_key(api_key_file)\n",
    "#         self.client = OpenAI(api_key=self.api_key)\n",
    "#         self.siamese_model = self.load_siamese_model(siamese_model_path)\n",
    "#         self.threshold = threshold\n",
    "#         self.jury_size = jury_size\n",
    "#         self.known_good_images = self.preload_known_good_images()\n",
    "#         self.headers = {\n",
    "#             \"Content-Type\": \"application/json\",\n",
    "#             \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "#         }\n",
    "        \n",
    "#     def load_api_key(self, filename):\n",
    "#         try:\n",
    "#             with open(filename, 'r') as file:\n",
    "#                 return file.read().strip()\n",
    "#         except FileNotFoundError:\n",
    "#             raise Exception(f\"API key file not found: {filename}\")\n",
    "\n",
    "#     def preload_known_good_images(self):\n",
    "#         # Your existing method to preload images\n",
    "#         print(\"Preloading known good images...\")\n",
    "#         image_paths = []\n",
    "#         for root, dirs, files in os.walk(self.known_good_images_folder):\n",
    "#             for file in files:\n",
    "#                 if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                     full_path = os.path.join(root, file)\n",
    "#                     image_paths.append(full_path)\n",
    "#         return image_paths\n",
    "#         # Cache known good images if needed here\n",
    "        \n",
    "#     # Continue to define ModelPredictor class\n",
    "#     def load_siamese_model(self, siamese_model_path):\n",
    "#         # Define the base network architecture\n",
    "#         def initialize_base_network(input_shape):\n",
    "#             input = Input(shape=input_shape)\n",
    "#             x = Conv2D(64, (3, 3), activation='relu')(input)\n",
    "#             x = MaxPooling2D((2, 2))(x)\n",
    "#             x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "#             x = MaxPooling2D((2, 2))(x)\n",
    "#             x = Flatten()(x)\n",
    "#             x = Dense(128, activation='relu')(x)\n",
    "#             return Model(input, x)\n",
    "\n",
    "#         # Rebuild the Siamese network architecture\n",
    "#         input_shape = (152, 152, 1)\n",
    "#         base_network = initialize_base_network(input_shape)\n",
    "#         input_a = Input(shape=input_shape)\n",
    "#         input_b = Input(shape=input_shape)\n",
    "#         processed_a = base_network(input_a)\n",
    "#         processed_b = base_network(input_b)\n",
    "#         distance = Lambda(lambda tensors: tf.sqrt(tf.reduce_sum(tf.square(tensors[0] - tensors[1]), axis=1, keepdims=True)))([processed_a, processed_b])\n",
    "#         model = Model([input_a, input_b], distance)\n",
    "#         model.load_weights(siamese_model_path)  # Load the saved model or weights\n",
    "#         print(\"Siamese model loaded successfully.\")\n",
    "#         return model\n",
    "\n",
    "#     def predict_siamese(self, image_path=None, coordinates=None):\n",
    "#         if coordinates:\n",
    "#             # Capture the screen if coordinates are provided\n",
    "#             captured_image = self.capture_screen(coordinates)\n",
    "#             # Convert the captured image to grayscale and resize it\n",
    "#             image = cv2.cvtColor(captured_image, cv2.COLOR_BGR2GRAY)\n",
    "#             image = cv2.resize(image, (152, 152))\n",
    "#         elif image_path:\n",
    "#             # Process the image from file path\n",
    "#             image = self.preprocess_image(image_path)\n",
    "#         else:\n",
    "#             raise ValueError(\"Either image_path or coordinates must be provided.\")\n",
    "        \n",
    "#         image = np.expand_dims(image, axis=0)  # Adjust as necessary for the model input\n",
    "    \n",
    "#         # Randomly select a subset of known good images to compare against\n",
    "#         selected_good_images = random.sample(self.known_good_images, min(self.jury_size, len(self.known_good_images)))\n",
    "#         votes = []\n",
    "    \n",
    "#         for known_good_image_path in selected_good_images:\n",
    "#             known_good_image = self.preprocess_image(known_good_image_path)\n",
    "#             known_good_image = np.expand_dims(known_good_image, axis=0)  # Adjust as necessary\n",
    "    \n",
    "#             # Prepare the pair\n",
    "#             image_pair = [image, known_good_image]\n",
    "    \n",
    "#             # Make prediction\n",
    "#             prediction_distance = self.siamese_model.predict(image_pair)\n",
    "#             is_similar = prediction_distance < self.threshold  # Threshold to determine similarity\n",
    "    \n",
    "#             # Debugging output\n",
    "#             print(f\"Comparing {image_path if image_path else 'screen capture'} with {known_good_image_path}: Distance = {prediction_distance}, Similar = {is_similar}\")\n",
    "#             votes.append(is_similar)\n",
    "    \n",
    "#         # Calculate the majority vote\n",
    "#         num_similar = sum(votes)\n",
    "#         majority_similar = num_similar > len(votes) / 2\n",
    "#         print(f\"Total votes for 'Similar': {num_similar}/{len(votes)}. Final verdict: {'Normal' if majority_similar else 'Anomalous'}\")\n",
    "    \n",
    "#         return majority_similar\n",
    "\n",
    "#     def compare_to_known_images(self, captured_image, threshold=0.5, jury_size=3):\n",
    "#         processed_captured_image = self.preprocess_data(captured_image)\n",
    "#         verdicts = []\n",
    "\n",
    "#         for _ in range(jury_size):\n",
    "#             comparison_image = np.random.choice(self.known_good_images)\n",
    "#             prediction = self.siamese_model.predict([processed_captured_image, comparison_image])\n",
    "#             verdicts.append(prediction < threshold)\n",
    "\n",
    "#         # Determine if the majority verdict is 'similar' or 'dissimilar'\n",
    "#         final_verdict = sum(verdicts) >= jury_size / 2\n",
    "#         return final_verdict\n",
    "    \n",
    "#     def evaluate_image(self, coordinates):\n",
    "#         # Capture the image from screen coordinates\n",
    "#         captured_image = self.capture_screen(coordinates)\n",
    "\n",
    "#         # Compare to known images to get a verdict\n",
    "#         is_normal = self.compare_to_known_images(captured_image)\n",
    "\n",
    "#         return is_normal\n",
    "\n",
    "#     def preprocess_image(self, img_path: str, target_size=(152, 152)):\n",
    "#         try:\n",
    "#             image = load_img(img_path, target_size=target_size, color_mode='grayscale')\n",
    "#             image = img_to_array(image)\n",
    "#             image /= 255.0  # Normalize to [0, 1]\n",
    "#             if image.shape[-1] == 1:  # Check if image is grayscale\n",
    "#                 image = image.squeeze(-1)  # Remove the channels dimension if grayscale\n",
    "#         except FileNotFoundError as e:\n",
    "#             print(f\"Failed to open image at {img_path}: {e}\")\n",
    "#             return None\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing image at {img_path}: {e}\")\n",
    "#             return None\n",
    "#         return image \n",
    "\n",
    "#     def capture_screen(self, coordinates):\n",
    "#         \"\"\" Capture the screen area defined by coordinates. \"\"\"\n",
    "#         screenshot = ImageGrab.grab(bbox=coordinates)\n",
    "#         return np.array(screenshot, dtype=np.uint8)  # Ensure dtype is uint8\n",
    "\n",
    "#     def encode_image(self, image):\n",
    "#         \"\"\" Encode image array to base64 string. \"\"\"\n",
    "#         if isinstance(image, np.ndarray):\n",
    "#             # Convert numpy array to PIL Image if it's not already one\n",
    "#             image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "#         buffer = io.BytesIO()\n",
    "#         image.save(buffer, format=\"JPEG\")\n",
    "#         return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "\n",
    "#     def describe_image(self, image_path=None, coordinates=None, role_description=\"User\", image_description_directive=\"Describe the image\"):\n",
    "#         if image_path:\n",
    "#             image = self.preprocess_image(image_path)\n",
    "#         elif coordinates:\n",
    "#             image = self.capture_screen(coordinates)\n",
    "#         else:\n",
    "#             raise ValueError(\"Either image_path or coordinates must be provided.\")\n",
    "    \n",
    "#         if image is None:\n",
    "#             raise ValueError(\"Failed to load or process image.\")\n",
    "    \n",
    "#         base64_image = self.encode_image(image)\n",
    "    \n",
    "    \n",
    "#         # Ensure image is properly formatted as a numpy array if not done in preprocess\n",
    "#         if not isinstance(image, np.ndarray):\n",
    "#             raise ValueError(\"Processed image must be a numpy array.\")\n",
    "    \n",
    "#         # Encode the processed image to base64\n",
    "#         base64_image = self.encode_image(image)\n",
    "        \n",
    "#         # Construct payload\n",
    "#         payload = {\n",
    "#             \"model\": \"gpt-4-turbo\",\n",
    "#             \"messages\": [\n",
    "#                 {\n",
    "#                     \"role\": \"system\",\n",
    "#                     \"content\": role_description\n",
    "#                 },\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": [\n",
    "#                         {\n",
    "#                             \"type\": \"text\",\n",
    "#                             \"text\": image_description_directive\n",
    "#                         },\n",
    "#                         {\n",
    "#                             \"type\": \"image_url\",\n",
    "#                             \"image_url\": {\n",
    "#                                 \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#                             }\n",
    "#                         }\n",
    "#                     ]\n",
    "#                 }\n",
    "#             ],\n",
    "#             \"max_tokens\": 300\n",
    "#         }\n",
    "    \n",
    "#         # Send request\n",
    "#         response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self.headers, json=payload)\n",
    "#         if response.status_code != 200:\n",
    "#             print(\"Error from API:\", response.status_code, response.text)\n",
    "#             return None\n",
    "    \n",
    "#         try:\n",
    "#             description = response.json()['choices'][0]['message']['content']\n",
    "#             print(\"Image Description:\", description)\n",
    "#             return description\n",
    "#         except KeyError as e:\n",
    "#             print(\"Failed to parse API response:\", response.json())\n",
    "#             raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f9106e5-418c-4d33-b696-10f324e0bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from PIL import Image, ImageGrab\n",
    "# import base64\n",
    "# import io\n",
    "# from tensorflow.keras.models import Model, load_model\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "# import tensorflow as tf\n",
    "# from openai import OpenAI\n",
    "\n",
    "# class ModelPredictor:\n",
    "#     def __init__(self, siamese_model_path, known_good_images_folder, api_key_file='Eyball-OpenAI_key.txt', threshold=0.5, jury_size=12):\n",
    "#         self.siamese_model_path = siamese_model_path\n",
    "#         self.known_good_images_folder = known_good_images_folder\n",
    "#         self.api_key = self.load_api_key(api_key_file)\n",
    "#         self.client = OpenAI(api_key=self.api_key)\n",
    "#         self.siamese_model = self.load_siamese_model()\n",
    "#         self.threshold = threshold\n",
    "#         self.jury_size = jury_size\n",
    "#         self.known_good_images = self.preload_known_good_images()\n",
    "#         self.headers = {\n",
    "#             \"Content-Type\": \"application/json\",\n",
    "#             \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "#         }\n",
    "\n",
    "#     def load_api_key(self, filename):\n",
    "#         try:\n",
    "#             with open(filename, 'r') as file:\n",
    "#                 return file.read().strip()\n",
    "#         except FileNotFoundError:\n",
    "#             raise Exception(f\"API key file not found: {filename}\")\n",
    "\n",
    "#     def preload_known_good_images(self):\n",
    "#         print(\"Preloading known good images...\")\n",
    "#         image_paths = []\n",
    "#         for root, dirs, files in os.walk(self.known_good_images_folder):\n",
    "#             for file in files:\n",
    "#                 if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                     full_path = os.path.join(root, file)\n",
    "#                     image_paths.append(full_path)\n",
    "#         return image_paths\n",
    "\n",
    "#     def load_siamese_model(self):\n",
    "#         input_shape = (152, 152, 1)\n",
    "#         input_a = Input(shape=input_shape)\n",
    "#         input_b = Input(shape=input_shape)\n",
    "#         base_network = self.initialize_base_network(input_shape)\n",
    "#         processed_a = base_network(input_a)\n",
    "#         processed_b = base_network(input_b)\n",
    "#         distance = Lambda(lambda tensors: tf.sqrt(tf.reduce_sum(tf.square(tensors[0] - tensors[1]), axis=1)))([processed_a, processed_b])\n",
    "#         model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "#         model.load_weights(self.siamese_model_path)\n",
    "#         print(\"Siamese model loaded successfully.\")\n",
    "#         return model\n",
    "\n",
    "#     def initialize_base_network(self, input_shape):\n",
    "#         input = Input(shape=input_shape)\n",
    "#         x = Conv2D(64, (3, 3), activation='relu')(input)\n",
    "#         x = MaxPooling2D((2, 2))(x)\n",
    "#         x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "#         x = MaxPooling2D((2, 2))(x)\n",
    "#         x = Flatten()(x)\n",
    "#         x = Dense(128, activation='relu')(x)\n",
    "#         return Model(inputs=input, outputs=x)\n",
    "\n",
    "#     def preprocess_image(self, image=None, image_path=None):\n",
    "#         if image_path is not None:\n",
    "#             # Load image from file path\n",
    "#             try:\n",
    "#                 image = Image.open(image_path)\n",
    "#                 image = image.convert('L')  # Convert to grayscale\n",
    "#             except FileNotFoundError as e:\n",
    "#                 print(f\"Failed to open image at {image_path}: {e}\")\n",
    "#                 return None\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing image at {image_path}: {e}\")\n",
    "#                 return None\n",
    "#         elif image is None:\n",
    "#             print(\"No image provided for preprocessing\")\n",
    "#             return None\n",
    "    \n",
    "#         # Resize and normalize the image\n",
    "#         target_size = (152, 152)\n",
    "#         image = image.resize(target_size)\n",
    "#         image = np.array(image, dtype=np.uint8)\n",
    "#         image = image / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "#         if image.ndim == 2:  # Ensure image has 3 dimensions\n",
    "#             image = np.expand_dims(image, -1)\n",
    "    \n",
    "#         return image\n",
    "\n",
    "\n",
    "#     def capture_screen(self, coordinates):\n",
    "#         screenshot = ImageGrab.grab(bbox=coordinates)\n",
    "#         return np.array(screenshot, dtype=np.uint8)  # Ensure dtype is uint8\n",
    "\n",
    "#     def predict_siamese(self, image_path=None, coordinates=None):\n",
    "#         if coordinates:\n",
    "#             print(\"Capturing screen...\")\n",
    "#             captured_image = self.capture_screen(coordinates)\n",
    "#             if captured_image is None:\n",
    "#                 print(\"Failed to capture screen\")\n",
    "#                 return None\n",
    "#             image = self.preprocess_image(captured_image)\n",
    "#         elif image_path:\n",
    "#             image = self.preprocess_image(image_path)\n",
    "#             if image is None:\n",
    "#                 print(\"Failed to preprocess image from path\")\n",
    "#                 return None\n",
    "#         else:\n",
    "#             raise ValueError(\"Either image_path or coordinates must be provided.\")\n",
    "        \n",
    "#         if image is None:\n",
    "#             print(\"No image to process\")\n",
    "#             return None\n",
    "        \n",
    "#         image = np.expand_dims(image, axis=0)  # Adjust as necessary for the model input\n",
    "\n",
    "#         print(\"Image loaded and processed, predicting...\")\n",
    "#         votes = []\n",
    "#         for known_good_image_path in random.sample(self.known_good_images, min(self.jury_size, len(self.known_good_images))):\n",
    "#             known_good_image = self.preprocess_image(known_good_image_path)\n",
    "#             if known_good_image is None:\n",
    "#                 continue  # Skip if image can't be processed\n",
    "#             known_good_image = np.expand_dims(known_good_image, axis=0)\n",
    "\n",
    "#             # Prepare the pair\n",
    "#             image_pair = [image, known_good_image]\n",
    "\n",
    "#             # Make prediction\n",
    "#             prediction_distance = self.siamese_model.predict(image_pair)\n",
    "#             is_similar = prediction_distance < self.threshold  # Threshold to determine similarity\n",
    "#             print(f\"Comparing {image_path if image_path else 'screen capture'} with {known_good_image_path}: Distance = {prediction_distance}, Similar = {is_similar}\")\n",
    "#             votes.append(is_similar)\n",
    "\n",
    "#         # Calculate the majority vote\n",
    "#         num_similar = sum(votes)\n",
    "#         majority_similar = num_similar > len(votes) / 2\n",
    "#         print(f\"Total votes for 'Similar': {num_similar}/{len(votes)}. Final verdict: {'Normal' if majority_similar else 'Anomalous'}\")\n",
    "\n",
    "#         return 'Normal' if majority_similar else 'Anomalous'\n",
    "\n",
    "\n",
    "#     def send_image_to_api(self, base64_image, role_description, image_description_directive):\n",
    "#         print(\"Sending image to API...\")\n",
    "#         payload = {\n",
    "#             \"model\": \"gpt-4-turbo\",\n",
    "#             \"messages\": [\n",
    "#                 {\n",
    "#                     \"role\": \"system\",\n",
    "#                     \"content\": role_description\n",
    "#                 },\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": [\n",
    "#                         {\n",
    "#                             \"type\": \"text\",\n",
    "#                             \"text\": image_description_directive\n",
    "#                         },\n",
    "#                         {\n",
    "#                             \"type\": \"image_url\",\n",
    "#                             \"image_url\": {\n",
    "#                                 \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#                             }\n",
    "#                         }\n",
    "#                     ]\n",
    "#                 }\n",
    "#             ],\n",
    "#             \"max_tokens\": 300\n",
    "#         }\n",
    "#         response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self.headers, json=payload)\n",
    "#         if response.status_code != 200:\n",
    "#             print(\"Error from API:\", response.status_code, response.text)\n",
    "#             return None\n",
    "\n",
    "#         try:\n",
    "#             description = response.json()['choices'][0]['message']['content']\n",
    "#             return description\n",
    "#         except KeyError as e:\n",
    "#             print(\"Failed to parse API response:\", response.json())\n",
    "#             raise e\n",
    "\n",
    "\n",
    "#     def describe_image(self, image_path=None, coordinates=None, role_description=\"User\", image_description_directive=\"Describe the image\"):\n",
    "#         try:\n",
    "#             if coordinates:\n",
    "#                 print(\"Capturing screen for description...\")\n",
    "#                 image = self.capture_screen(coordinates)\n",
    "#             elif image_path:\n",
    "#                 print(\"Loading image from path for description...\")\n",
    "#                 image = self.preprocess_image(image_path)\n",
    "#             else:\n",
    "#                 raise ValueError(\"Either image_path or coordinates must be provided.\")\n",
    "\n",
    "#             if image is None:\n",
    "#                 raise ValueError(\"Failed to load or process image.\")\n",
    "\n",
    "#             print(\"Encoding image for API request...\")\n",
    "#             base64_image = self.encode_image(image)\n",
    "#             description = self.send_image_to_api(base64_image, role_description, image_description_directive)\n",
    "#             print(\"Description received.\")\n",
    "#             return description\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in describe_image: {str(e)}\")\n",
    "#             return None\n",
    "\n",
    "#     def compare_images(self, test_image):\n",
    "#         print(\"Comparing images...\")\n",
    "#         # Similar implementation as previously described for Siamese model prediction\n",
    "#         pass\n",
    "\n",
    "#     def encode_image(self, image):\n",
    "#         \"\"\"Converts a numpy array image to JPEG base64.\"\"\"\n",
    "#         try:\n",
    "#             if image.ndim == 3 and image.shape[2] == 1:  # Check if it's single-channel\n",
    "#                 image = image.squeeze(-1)  # Remove the last dimension if it's single-channel\n",
    "#             if isinstance(image, np.ndarray):\n",
    "#                 # Ensure the data type is uint8\n",
    "#                 image = (image * 255).clip(0, 255).astype(np.uint8)\n",
    "#                 # Convert numpy array to PIL Image\n",
    "#                 if image.ndim == 2:  # Grayscale\n",
    "#                     image = Image.fromarray(image, 'L')\n",
    "#                 else:\n",
    "#                     image = Image.fromarray(image, 'RGB')\n",
    "#             buffer = io.BytesIO()\n",
    "#             image.save(buffer, format=\"JPEG\")\n",
    "#             encoded_string = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "#             return encoded_string\n",
    "#         except Exception as e:\n",
    "#             raise ValueError(f\"Error encoding image: {str(e)}\")\n",
    "\n",
    "#     def preprocess_image_from_array(self, image_array):\n",
    "#         \"\"\"Preprocess an image given as a NumPy array.\"\"\"\n",
    "#         if image_array.ndim == 3 and image_array.shape[-1] == 3:  # Assuming RGB input\n",
    "#             image = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "#         image = cv2.resize(image, (152, 152))\n",
    "#         image = np.array(image, dtype=np.float32) / 255.0\n",
    "#         image = np.expand_dims(image, axis=-1)  # Ensure it has a single channel if needed\n",
    "#         return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6007f44-6ae1-4e43-bb68-0542ef0e6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageGrab\n",
    "import base64\n",
    "import io\n",
    "import requests\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "import tensorflow as tf\n",
    "from openai import OpenAI\n",
    "\n",
    "class ModelPredictor:\n",
    "    def __init__(self, siamese_model_path, known_good_images_folder, api_key_file='Eyball-OpenAI_key.txt', threshold=0.5, jury_size=12):\n",
    "        self.siamese_model_path = siamese_model_path\n",
    "        self.known_good_images_folder = known_good_images_folder\n",
    "        self.api_key = self.load_api_key(api_key_file)\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "        self.siamese_model = self.load_siamese_model()\n",
    "        self.threshold = threshold\n",
    "        self.jury_size = jury_size\n",
    "        self.known_good_images = self.preload_known_good_images()\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "\n",
    "    def load_api_key(self, filename):\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                return file.read().strip()\n",
    "        except FileNotFoundError:\n",
    "            raise Exception(f\"API key file not found: {filename}\")\n",
    "\n",
    "    def preload_known_good_images(self):\n",
    "        print(\"Preloading known good images...\")\n",
    "        image_paths = []\n",
    "        for root, dirs, files in os.walk(self.known_good_images_folder):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    image_paths.append(full_path)\n",
    "        return image_paths\n",
    "\n",
    "    def load_siamese_model(self):\n",
    "        input_shape = (152, 152, 1)\n",
    "        input_a = Input(shape=input_shape)\n",
    "        input_b = Input(shape=input_shape)\n",
    "        base_network = self.initialize_base_network(input_shape)\n",
    "        processed_a = base_network(input_a)\n",
    "        processed_b = base_network(input_b)\n",
    "        distance = Lambda(lambda tensors: tf.sqrt(tf.reduce_sum(tf.square(tensors[0] - tensors[1]), axis=1)))([processed_a, processed_b])\n",
    "        model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "        model.load_weights(self.siamese_model_path)\n",
    "        print(\"Siamese model loaded successfully.\")\n",
    "        return model\n",
    "\n",
    "    def initialize_base_network(self, input_shape):\n",
    "        input = Input(shape=input_shape)\n",
    "        x = Conv2D(64, (3, 3), activation='relu')(input)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        return Model(inputs=input, outputs=x)\n",
    "\n",
    "    \n",
    "    def preprocess_image(self, image=None, image_path=None):\n",
    "        if image_path:\n",
    "            # Load image from file path\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Failed to open image at {image_path}: {e}\")\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image at {image_path}: {e}\")\n",
    "                return None\n",
    "        if isinstance(image, np.ndarray):\n",
    "            # Convert to PIL Image for consistent processing\n",
    "            image = Image.fromarray(image.astype('uint8'))\n",
    "    \n",
    "        if image is None:\n",
    "            print(\"No image provided for preprocessing\")\n",
    "            return None\n",
    "    \n",
    "        # Convert to grayscale and resize\n",
    "        image = image.convert('L')  # Convert to grayscale\n",
    "        target_size = (152, 152)\n",
    "        image = image.resize(target_size)\n",
    "        image = np.array(image, dtype=np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "        if image.ndim == 2:  # Ensure image has 3 dimensions if it's still 2D\n",
    "            image = np.expand_dims(image, -1)\n",
    "    \n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def capture_screen(self, coordinates):\n",
    "        screenshot = ImageGrab.grab(bbox=coordinates)\n",
    "        return np.array(screenshot, dtype=np.uint8)  # Ensure dtype is uint8\n",
    "\n",
    "    def predict_siamese(self, image_path=None, coordinates=None):\n",
    "        if coordinates:\n",
    "            print(\"Capturing screen...\")\n",
    "            captured_image = self.capture_screen(coordinates)\n",
    "            if captured_image is None:\n",
    "                print(\"Failed to capture screen\")\n",
    "                return None\n",
    "            image = self.preprocess_image(image=captured_image)\n",
    "        elif image_path:\n",
    "            image = self.preprocess_image(image_path=image_path)\n",
    "            if image is None:\n",
    "                print(\"Failed to preprocess image from path\")\n",
    "                return None\n",
    "        else:\n",
    "            raise ValueError(\"Either image_path or coordinates must be provided.\")\n",
    "\n",
    "    def predict_siamese(self, image_path=None, coordinates=None):\n",
    "        if coordinates:\n",
    "            print(\"Capturing screen...\")\n",
    "            captured_image = self.capture_screen(coordinates)\n",
    "            if captured_image is None:\n",
    "                print(\"Failed to capture screen\")\n",
    "                return None\n",
    "            image = self.preprocess_image(image=captured_image)\n",
    "        elif image_path:\n",
    "            image = self.preprocess_image(image_path=image_path)\n",
    "        else:\n",
    "            raise ValueError(\"Either image_path or coordinates must be provided.\")\n",
    "    \n",
    "        if image is None:\n",
    "            print(\"No image to process\")\n",
    "            return None\n",
    "    \n",
    "        image = np.expand_dims(image, axis=0)  # Adjust as necessary for the model input\n",
    "    \n",
    "        print(\"Image loaded and processed, predicting...\")\n",
    "\n",
    "        votes = []\n",
    "        for known_good_image_path in random.sample(self.known_good_images, min(self.jury_size, len(self.known_good_images))):\n",
    "            known_good_image = self.preprocess_image(image_path=known_good_image_path)\n",
    "            if known_good_image is None:\n",
    "                continue  # Skip if image can't be processed\n",
    "            known_good_image = np.expand_dims(known_good_image, axis=0)\n",
    "\n",
    "            # Prepare the pair\n",
    "            image_pair = [image, known_good_image]\n",
    "\n",
    "            # Make prediction\n",
    "            prediction_distance = self.siamese_model.predict(image_pair)\n",
    "            is_similar = prediction_distance < self.threshold  # Threshold to determine similarity\n",
    "            print(f\"Comparing {image_path if image_path else 'screen capture'} with {known_good_image_path}: Distance = {prediction_distance}, Similar = {is_similar}\")\n",
    "            votes.append(is_similar)\n",
    "\n",
    "        # Calculate the majority vote\n",
    "        num_similar = sum(votes)\n",
    "        majority_similar = num_similar > len(votes) / 2\n",
    "        print(f\"Total votes for 'Similar': {num_similar}/{len(votes)}. Final verdict: {'Normal' if majority_similar else 'Anomalous'}\")\n",
    "\n",
    "        return 'Normal' if majority_similar else 'Anomalous'\n",
    "\n",
    "    def describe_image(self, image_path=None, coordinates=None, role_description=\"User\", image_description_directive=\"Describe the image\"):\n",
    "        try:\n",
    "            if coordinates:\n",
    "                print(\"Capturing screen for description...\")\n",
    "                image = self.capture_screen(coordinates)\n",
    "            elif image_path:\n",
    "                print(\"Loading image from path for description...\")\n",
    "                image = self.preprocess_image(image_path=image_path)\n",
    "            else:\n",
    "                raise ValueError(\"Either image_path or coordinates must be provided.\")\n",
    "    \n",
    "            if image is None:\n",
    "                raise ValueError(\"Failed to load or process image.\")\n",
    "    \n",
    "            print(\"Encoding image for API request...\")\n",
    "            base64_image = self.encode_image(image)\n",
    "            description = self.send_image_to_api(base64_image, role_description, image_description_directive)\n",
    "            print(\"Description received.\")\n",
    "            return description\n",
    "        except Exception as e:\n",
    "            print(f\"Error in describe_image: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        \"\"\"Converts a numpy array image to JPEG base64.\"\"\"\n",
    "        try:\n",
    "            if image.ndim == 3 and image.shape[2] == 1:  # Check if it's single-channel\n",
    "                image = image.squeeze(-1)  # Remove the last dimension if it's single-channel\n",
    "            if isinstance(image, np.ndarray):\n",
    "                # Ensure the data type is uint8\n",
    "                image = (image * 255).clip(0, 255).astype(np.uint8)\n",
    "                # Convert numpy array to PIL Image\n",
    "                if image.ndim == 2:  # Grayscale\n",
    "                    image = Image.fromarray(image, 'L')\n",
    "                else:\n",
    "                    image = Image.fromarray(image, 'RGB')\n",
    "            buffer = io.BytesIO()\n",
    "            image.save(buffer, format=\"JPEG\")\n",
    "            encoded_string = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "            return encoded_string\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error encoding image: {str(e)}\")\n",
    "\n",
    "    def send_image_to_api(self, base64_image, role_description, image_description_directive):\n",
    "        print(\"Sending image to API...\")\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4-turbo\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": role_description\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": image_description_directive\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self.headers, json=payload)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Error from API:\", response.status_code, response.text)\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            description = response.json()['choices'][0]['message']['content']\n",
    "            return description\n",
    "        except KeyError as e:\n",
    "            print(\"Failed to parse API response:\", response.json())\n",
    "            raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fc401056-204c-4548-b9c7-47029d87dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese model loaded successfully.\n",
      "Preloading known good images...\n"
     ]
    }
   ],
   "source": [
    "predictor = ModelPredictor(siamese_model_path, known_good_images_folder, api_key_file, threshold, jury_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a472b6e-13fd-44de-a829-6039ab33bdb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing screen...\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\59924dfb-9fba-44ad-b88a-1438253724f9_1.png: Distance = [1.1311841], Similar = [False]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\1a274c9a-0959-4a2b-9ab7-8842fc2dee70_0.png: Distance = [1.1311841], Similar = [False]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\2e8223fe-01e0-42dc-bdb1-0aaa74bdff9a_1.png: Distance = [1.1311841], Similar = [False]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\dummy_class\\9b92280d-d250-4cef-9538-311449bee364.png: Distance = [1.1311841], Similar = [False]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\067663c0-bb3b-426e-938c-6b4eb7c59e88_0.png: Distance = [1.097731], Similar = [False]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\bf20a085-6196-4bfe-84bb-5b6a82fd6e9b_1.png: Distance = [0.7165582], Similar = [False]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\668870c7-32fb-4acb-96cf-26fa9e39daae_0.png: Distance = [1.1311841], Similar = [False]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\88d047a2-d8db-42ad-a5a6-cbf337a8b342_1.png: Distance = [1.0261246], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\4f67c533-e78d-4ed3-9341-8dc5075cee54_0.png: Distance = [1.1311841], Similar = [False]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\e9842c6e-2e6a-4868-94de-dc9a22044e40_0.png: Distance = [0.8781072], Similar = [False]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3164fabf-10b0-4721-91df-6ebea9169a89_1.png: Distance = [1.1311841], Similar = [False]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Comparing screen capture with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\45807559-6251-47ad-87c8-424d54243981_0.png: Distance = [1.1311841], Similar = [False]\n",
      "Total votes for 'Similar': [0]/12. Final verdict: Anomalous\n",
      "Siamese result Anomalous\n",
      "Capturing screen for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'*** ANOMALOUS ***'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture and evaluate an area of the screen ...\n",
    "\n",
    "left = 10\n",
    "right = 500\n",
    "top = 10\n",
    "bottom = 200\n",
    "\n",
    "siamese_result = predictor.predict_siamese(coordinates=(left, top, right, bottom))\n",
    "print (\"Siamese result\", siamese_result)\n",
    "\n",
    "predictor.describe_image(coordinates=(left, top, right, bottom), role_description=role, image_description_directive=image_description_directive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "777f8e1c-44b0-492d-b56a-711023600ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\8d86ad60-582d-4409-990b-9f6d15ef6374_0.png: Distance = [0.9324705], Similar = [False]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\dummy_class\\d4c9283f-bee6-4d8b-9a37-86fd1dc377b9.png: Distance = [1.0572661], Similar = [False]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\4782ecdd-98b0-479b-8e07-512a009783d3_1.png: Distance = [1.0572661], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\234985a4-b400-4dd8-85a4-9885251dee0c_1.png: Distance = [1.0566574], Similar = [False]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\7f0d8a84-1c00-4d94-b90d-c441dbb82e38_1.png: Distance = [0.3892048], Similar = [ True]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\5641fafc-3399-4108-86b9-0dc6b1dfed30_0.png: Distance = [1.0572661], Similar = [False]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\f9554b0d-77bc-4b51-b044-7fc8918a614b_0.png: Distance = [0.97104007], Similar = [False]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\0a57d7f1-38a6-45f7-ac99-af5b7b94d4fd_1.png: Distance = [0.7598214], Similar = [False]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\58034bdd-3821-463d-8dc4-8e16501521a6_1.png: Distance = [1.0572661], Similar = [False]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\d8412fb6-0422-4ab1-bad5-580298f9155c_1.png: Distance = [1.0572661], Similar = [False]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\dummy_class\\0a57d7f1-38a6-45f7-ac99-af5b7b94d4fd.png: Distance = [1.0419166], Similar = [False]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing C:\\temp\\engineer_typing3.png with D:\\training_images\\test\\valid\\dummy_class\\c2727757-431e-4168-9996-3b0bf36b935f.png: Distance = [1.0572661], Similar = [False]\n",
      "Total votes for 'Similar': [1]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description *** ANOMALOUS ***\n"
     ]
    }
   ],
   "source": [
    "# Or (from here on) pass in a captured and saved file\n",
    "\n",
    "test_image_path = r'C:\\temp\\engineer_typing3.png'\n",
    "print(\"Model predicts\", predictor.predict_siamese(image_path=test_image_path))\n",
    "\n",
    "actual_description = predictor.describe_image(image_path=test_image_path, role_description=role, image_description_directive=image_description_directive)\n",
    "print (\"LLM description\", actual_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c77b15a7-e3e2-4787-86fb-1f235064923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\dummy_class\\7b786536-f33f-4f61-b29a-f9f8aad246ea.png: Distance = [0.7493696], Similar = [False]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\5d8c80cb-9ae9-409c-9d20-cff63c7ba7c4_1.png: Distance = [0.9431377], Similar = [False]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\bad4fb22-813b-48b8-b28a-6f3818632dc6_0.png: Distance = [1.0546803], Similar = [False]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\e2ef633b-06a5-4bce-b2ee-b4e97a666fe4_1.png: Distance = [1.1204376], Similar = [False]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\7c04ad64-9d77-4d95-9409-552780caa4a1_1.png: Distance = [1.0154984], Similar = [False]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\e3846bae-45fa-456a-af4e-a04a6604d3b1_1.png: Distance = [1.168402], Similar = [False]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\89091e5a-2f7c-4f07-b0b9-e8998af20388_0.png: Distance = [1.168402], Similar = [False]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\bf8fd355-dfc7-41ff-af3f-388ebd71622f_0.png: Distance = [1.168402], Similar = [False]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\dummy_class\\45807559-6251-47ad-87c8-424d54243981.png: Distance = [1.168402], Similar = [False]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\44e8548a-6754-49be-9e7a-a865d70517b8_1.png: Distance = [1.1422809], Similar = [False]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\6eb2d6ae-b679-49cc-a776-b82ca7f389be_0.png: Distance = [1.168402], Similar = [False]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\Custom_invalid\\cat.jpg with D:\\training_images\\test\\valid\\dummy_class\\2493c6e8-224f-439f-886a-77099cc47ab9.png: Distance = [1.168402], Similar = [False]\n",
      "Total votes for 'Similar': [0]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description *** ANOMALOUS ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\Custom_invalid\\cat.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f01e690-9589-44e2-81a0-1ed654a10ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\6fd235e4-47ea-4877-be14-5c6b4b88bf7e_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\68e72bde-439f-4b9d-81ef-423d45f5b736_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\b82f984b-65f5-410f-be06-dbd910375dd1_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\f491fabe-538b-470e-9218-ee084b603fce_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\31c331ed-2a1b-4bba-9a6d-47c6622ef1d2_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3c142d11-80f8-4c46-9ea8-1b438e4d2a08_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\0031f42f-36dc-45f4-8cb8-e57ad73ad551_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3e2c8f1b-5b7c-4a4b-9005-0d1864e2646a_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\dummy_class\\56d56399-4565-425f-a7e3-8e0774c2f554.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\300d842a-583b-4b3a-a884-85743f038664_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\1a04046c-8815-4034-98e2-26d5aef3427e_1.png: Distance = [0.10072638], Similar = [ True]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg with D:\\training_images\\test\\valid\\dummy_class\\4c84c74d-134c-40bf-a45d-3c9db69ea1b3.png: Distance = [0.], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Model predicts Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description *** NORMAL ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\custom_test_valid\\internet_27f6574b96deb965217cff1aac35fc_gallery.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3207058d-10f5-44cc-9fb3-013e7bcafdc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\e9406de0-2d76-44a3-91bd-195efd0badd6_0.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\dummy_class\\3b5992f1-dfbf-486d-9281-14e4c5aa5947.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\e989e96d-4cf2-4923-a414-3f737f1ce3bd_0.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\dfae2e78-9e8f-4ab8-afd0-a3a63d024d6c_1.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\aaae8e98-5b03-43c9-b3b3-873520d9ba51_1.png: Distance = [0.07582414], Similar = [ True]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\7507d7b2-04f5-400c-976c-49665a33bf8c_0.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\7174f1a6-9714-4516-9044-729a4cefe486_0.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\d566f961-422d-4b79-8080-4488b9739980_1.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\aca0833a-0bf1-4712-bcab-4bb33cf57717_0.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\47036cc9-07e0-4bfd-b25f-df5565a882af_1.png: Distance = [0.14590386], Similar = [ True]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\52a6abd1-5252-47a1-bc4e-e43ee9e2bc98_1.png: Distance = [0.18324384], Similar = [ True]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Comparing D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\3758de8a-c9d2-4a9d-834c-bb12954691a4_1.png: Distance = [0.37434927], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Model predicts Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description *** NORMAL ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\custom_test_valid\\istockphoto-493741910-612x612.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23da4cc4-4cfc-4104-9605-9874b562844c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\9041adb7-47b1-45df-8836-52a3efb3163e_0.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\44028529-7778-4fa4-910f-60feeddbedfc_1.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\dummy_class\\de93f13d-70a0-4bdb-b7d1-38ce241e002c.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\dummy_class\\3308f48d-ce94-408f-9e75-c6446c24da61.png: Distance = [0.54152286], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\c25d266a-a314-40ca-8b2d-5685444c9374_0.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3dfc655c-1b9c-4565-b79f-bbc3aec79220_0.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\850926d7-3925-4725-90b7-d3fdab616b7c_0.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\ae9859ab-316b-4edf-a83c-8a3dc8e15517_1.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\dummy_class\\4c8c8bc2-bdaf-435a-9b72-9d34448d375b.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\b0cf7d7f-270e-4b4f-8202-986564dd0546_0.png: Distance = [0.71923923], Similar = [False]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\dummy_class\\517a20f8-8100-426a-a99d-76bfe6352b4d.png: Distance = [0.46683905], Similar = [ True]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg with D:\\training_images\\test\\valid\\dummy_class\\577f5aaf-4ce7-42e3-bfe9-2309e34f994b.png: Distance = [0.71923923], Similar = [False]\n",
      "Total votes for 'Similar': [1]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description *** NORMAL ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\custom_test_valid\\low-dose-lung-cancer-screening-with-lung-nodules.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e6a035cf-a390-4bc8-944a-3f1b8ed20866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\a3d34351-62ea-4373-8b67-9ec90f55f10b_0.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\dummy_class\\0825e22d-4170-403e-9632-daca06b5313a.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\b569d88a-0bba-4191-8556-74742cc13cfb_0.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\af506049-53cb-4068-9e5c-bff01f5d4798_0.png: Distance = [0.72347397], Similar = [False]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\c9128f12-639d-4024-8f74-fd7ffb95357c_1.png: Distance = [0.81995994], Similar = [False]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\0c2bae36-aecd-4568-b09c-5242706a6a3c_0.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\882d264f-6b7f-43bd-beb0-64ea22aa4335_0.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\5c1a5d3d-2c09-44cc-a428-e5891794c032_1.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\4a3639a1-b686-4ae3-b8e8-c48f3f7c1f45_1.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\0c3c862c-0dfb-4465-8653-983868e18707_0.png: Distance = [0.13763678], Similar = [ True]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\dummy_class\\e7c854ba-7cc3-41ee-b844-9de4c50de85e.png: Distance = [0.8484544], Similar = [False]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Comparing D:\\custom_invalid\\istockphoto-with_arrow.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\291dfb02-dedc-46f2-9b1a-0d5fb71970a0_0.png: Distance = [0.8484544], Similar = [False]\n",
      "Total votes for 'Similar': [1]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description This is a typical medical image, specifically a CT scan of the thoracic region. There are no textual overlays, annotations, or digital artifacts visible that suggest additions by PACS image viewer technology. \n",
      "\n",
      "*** NORMAL ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\custom_invalid\\istockphoto-with_arrow.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ed5e3eb-d7b5-4ef5-92a8-6fea7d72c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\e3826313-8744-4378-8796-536b7db7ed98_0.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\dummy_class\\f9c4529a-d2cf-4c73-8beb-d5502eeafce4.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\1bcb29aa-92e6-415c-8b9a-cb8477aaf506_1.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\7297dff2-4fc1-4782-ac30-3643220591e2_1.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\df13097c-cf2f-4866-82b9-3fb586630abe_1.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\55e1ced6-07c3-4ae4-ba9f-55f7be2fc317_0.png: Distance = [0.6057062], Similar = [False]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\6895714e-fec0-423a-a3ba-fd56a48de76e_0.png: Distance = [0.81202185], Similar = [False]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\c2028925-dc09-4639-a50f-d3f0b50d9344_0.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\dummy_class\\c9128f12-639d-4024-8f74-fd7ffb95357c.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\de32d902-a3d0-4605-bdc3-a8020a982cd6_0.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\7a2b2a57-e273-40f2-bdfc-b74714f625a1_0.png: Distance = [1.1311321], Similar = [False]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Comparing D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\6eda2603-0830-46a6-be9a-8a12f1938288_0.png: Distance = [0.8329406], Similar = [False]\n",
      "Total votes for 'Similar': [0]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description This is a typical medical image showing a CT scan of the chest. There are no textual overlays, annotations, or image processing artifacts visible that could have been added by PACS image viewer technology. *** NORMAL ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\custom_invalid\\Lung_abscess_-_CT_with_overlay.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "079be922-c1a5-42ec-96b9-2535a2bb4bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\00df59d8-dde0-469e-8fb8-792b2ef69778_1.png: Distance = [0.58764404], Similar = [False]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3c142d11-80f8-4c46-9ea8-1b438e4d2a08_1.png: Distance = [0.6476503], Similar = [False]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\dummy_class\\7be10dbf-0923-43ef-8257-48fd80882876.png: Distance = [0.6476503], Similar = [False]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\2db820b6-658a-47b8-964b-2ee047c88e84_1.png: Distance = [0.6476503], Similar = [False]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\dummy_class\\3bc7fca3-e831-4c16-ad82-eef2190c68e3.png: Distance = [0.6476503], Similar = [False]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\c7d4172e-8bdd-4b67-bc06-3f9817450f69_1.png: Distance = [0.37309176], Similar = [ True]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\733dc5ac-9793-4a7f-afef-bd4abd186d8d_1.png: Distance = [0.6476503], Similar = [False]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\ce3d052d-b28a-4243-8054-7d0405c5a1d3_0.png: Distance = [0.55426526], Similar = [False]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\22e442e4-0459-4b82-8f15-9846f5041cc9_1.png: Distance = [0.6476503], Similar = [False]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\dummy_class\\c7a0febe-8f82-4909-8919-f619f95a06fb.png: Distance = [0.29280612], Similar = [ True]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\dummy_class\\07a9cef1-8ebd-4af0-b1f7-790929436a86.png: Distance = [0.6476503], Similar = [False]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Comparing D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\2f7202c3-f1e7-4ff9-bb57-e7dd16b74145_1.png: Distance = [0.6476503], Similar = [False]\n",
      "Total votes for 'Similar': [2]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description The image features a medical scan (likely a CT or MRI) with an overlay of a textual message stating \"System Error Please restart.\" The presence of this textual overlay indicates an interruption or issue with the medical imaging system or post-processing software. This modification is not inherent to the capture of typical medical images.\n",
      "\n",
      "*** ANOMALOUS ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\Custom_invalid\\augmented_0abe42cc-623a-46f2-91ee-be4f339ff73b.png'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "015df824-0f4a-44a1-9cb5-6a46e27d5723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\dummy_class\\733dc5ac-9793-4a7f-afef-bd4abd186d8d.png: Distance = [0.98369527], Similar = [False]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\dummy_class\\35d5f4c2-091d-475d-be7a-49054211db11.png: Distance = [0.98369527], Similar = [False]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\8d1dd3a0-a116-4c86-a2f4-104a6408f61c_0.png: Distance = [0.6074642], Similar = [False]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3b12928e-9db7-4491-b1ff-032a074eacc2_1.png: Distance = [0.6223738], Similar = [False]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\52a6abd1-5252-47a1-bc4e-e43ee9e2bc98_0.png: Distance = [0.62064755], Similar = [False]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\dummy_class\\3b10fe7f-050c-4f36-944d-aa0b82564a18.png: Distance = [0.98369527], Similar = [False]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\a31c6ab1-7c7e-48fe-b59f-27b1059908e6_1.png: Distance = [0.7427405], Similar = [False]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\98fe354a-384e-4ecf-b3aa-b37a3c76d346_0.png: Distance = [0.98369527], Similar = [False]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3253e266-a321-4324-97a3-8a7196746e49_1.png: Distance = [0.98369527], Similar = [False]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\dummy_class\\cc3f84d0-f1bb-4bc2-82d5-0c0d95f92ff3.png: Distance = [0.38404512], Similar = [ True]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\8fff8910-e135-4c6d-9c94-e6b96176b7c7_0.png: Distance = [0.98369527], Similar = [False]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\4c84c74d-134c-40bf-a45d-3c9db69ea1b3_0.png: Distance = [0.98369527], Similar = [False]\n",
      "Total votes for 'Similar': [1]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description This image is a medical scan with multiple sharp black lines and shapes drawn over it, which are not part of a typical scan output by imaging modalities. These marks could represent annotations added post-image capture for educational or diagnostic review purposes. *** ANOMALOUS ***.\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'C:\\temp\\medical_image_zoomed_more_resized_modified_aspect_ratio_hairlines.png'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8cd5a7a2-e417-4c37-9575-96a642a02aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\b35deb13-2b88-48e2-8073-76d0ab060d04_0.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\21909e1b-e959-4682-ad49-4b7f7d51d043_1.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\dummy_class\\76553407-3d82-43bb-b2e2-077e8b38cd12.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\dummy_class\\b3fbf5e3-7e02-4605-a81a-5a21f26740e6.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\dummy_class\\b0991c40-26db-472a-8184-491d430aee9b.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\4492da1d-77fa-44d5-8376-cdccaf48e839_0.png: Distance = [0.51580507], Similar = [False]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\8fff8910-e135-4c6d-9c94-e6b96176b7c7_1.png: Distance = [0.4910329], Similar = [ True]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\23aae64a-c2ec-4ca9-82ae-a4ef546193c8_0.png: Distance = [0.12889457], Similar = [ True]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\a3b7aec5-d98f-4095-85a1-6f68e8fb5455_0.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\dummy_class\\8dcc351b-d91c-4714-b04a-df033e852c36.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\a24ddc1f-61fd-4f97-9e3a-525b6dce2fb3_1.png: Distance = [0.77528584], Similar = [False]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Comparing D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg with D:\\training_images\\test\\valid\\dummy_class\\9b92280d-d250-4cef-9538-311449bee364.png: Distance = [0.77528584], Similar = [False]\n",
      "Total votes for 'Similar': [2]/12. Final verdict: Anomalous\n",
      "Model predicts Anomalous\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description *** NORMAL ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\Custom_invalid\\internet-gettyimages-1320918955-612x612_small_label.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89c24324-c0d2-417a-8b98-d66e02cb70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\dummy_class\\e77a1fc0-79ca-448f-b40a-48422ddb97e2.png: Distance = [0.45146817], Similar = [ True]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\d2e9071f-9d08-443b-8f34-364ee11d9105_0.png: Distance = [0.45649433], Similar = [ True]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\7da50805-7bb4-445e-bcb7-e3e07fab64d6_1.png: Distance = [0.45649433], Similar = [ True]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\de93f13d-70a0-4bdb-b7d1-38ce241e002c_1.png: Distance = [0.45649433], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\e7e98622-ae69-4503-8042-13af4a7c825c_1.png: Distance = [0.42949212], Similar = [ True]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\f886b698-a548-4a15-8a02-e077c1eb566f_1.png: Distance = [0.37261], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\130d5b0b-045d-49b4-8775-7d02f63c902d_0.png: Distance = [0.45649433], Similar = [ True]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\88d047a2-d8db-42ad-a5a6-cbf337a8b342_1.png: Distance = [0.45649433], Similar = [ True]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\61b0a2d5-c859-4ceb-95e5-3cf38b70849f_1.png: Distance = [0.45649433], Similar = [ True]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\f9c0e3f3-aea2-406a-a4fd-115b64e27b0b_0.png: Distance = [0.395236], Similar = [ True]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\09a4578b-baae-4d5a-baf6-f8fae61e35a9_0.png: Distance = [0.08810949], Similar = [ True]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\ce0910de-d3e2-428d-8694-ee19bcc40d32_0.png: Distance = [0.03867218], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Model predicts Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "LLM description *** NORMAL ***\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r'D:\\Custom_test_valid\\internet-gettyimages-1322138871-612x612.jpg'\n",
    "print(\"Model predicts\", predictor.predict_siamese(test_image_path))\n",
    "\n",
    "predictor.describe_image(test_image_path, None, role, image_description_directive)\n",
    "print (\"LLM description\", predictor.describe_image(test_image_path, None, role, image_description_directive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2580e143-b43c-40fc-8788-316f7326d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_methods_simplified(base_folder, sample_size=40, jury_size=12, role=\"User\", image_description_directive=\"Describe the image\"):\n",
    "    valid_folder = os.path.join(base_folder, 'valid')\n",
    "    invalid_folder = os.path.join(base_folder, 'invalid')\n",
    "\n",
    "    # Ensure directories exist\n",
    "    if not os.path.exists(valid_folder) or not os.path.exists(invalid_folder):\n",
    "        raise ValueError(\"One or more image directories do not exist.\")\n",
    "\n",
    "    # List and sample images\n",
    "    valid_images = random.sample(os.listdir(valid_folder), min(sample_size, len(os.listdir(valid_folder))))\n",
    "    invalid_images = random.sample(os.listdir(invalid_folder), min(sample_size, len(os.listdir(invalid_folder))))\n",
    "\n",
    "    # Initialize predictions for both methods\n",
    "    predictions_siamese = []\n",
    "    predictions_gpt = []\n",
    "\n",
    "    # Initialize actual values\n",
    "    actuals = [1] * len(valid_images) + [0] * len(invalid_images)  # 1 for normal, 0 for anomalous\n",
    "\n",
    "    # Process sampled valid and invalid images\n",
    "    for filename in valid_images + invalid_images:\n",
    "        print (\"Filename\", filename)\n",
    "        folder = valid_folder if filename in valid_images else invalid_folder\n",
    "        image_path = os.path.join(folder, filename)\n",
    "\n",
    "        # Siamese Network Prediction\n",
    "        siamese_result = predictor.predict_siamese(image_path)\n",
    "        predictions_siamese.append(siamese_result)\n",
    "        print (\"Siamese result\", siamese_result)\n",
    "\n",
    "        # GPT Vision Direct Analysis Prediction\n",
    "        description_result = predictor.describe_image(image_path, None, role, image_description_directive)\n",
    "        predictions_gpt.append('NORMAL' in description_result)\n",
    "        print (\"API result\", description_result)\n",
    "\n",
    "    # Assuming that True/False predictions from Siamese network are correct and just need flattening:\n",
    "    predictions_siamese = [int(pred.flatten()[0]) for pred in predictions_siamese]\n",
    "    \n",
    "    # Convert GPT predictions from True/False to 0/1 as well:\n",
    "    predictions_gpt = [int(pred) for pred in predictions_gpt]\n",
    "    \n",
    "    # Recalculate the metrics:\n",
    "    accuracy_s = accuracy_score(actuals, predictions_siamese)\n",
    "    precision_s = precision_score(actuals, predictions_siamese)\n",
    "    recall_s = recall_score(actuals, predictions_siamese)\n",
    "    f1_s = f1_score(actuals, predictions_siamese)\n",
    "    \n",
    "    accuracy_g = accuracy_score(actuals, predictions_gpt)\n",
    "    precision_g = precision_score(actuals, predictions_gpt)\n",
    "    recall_g = recall_score(actuals, predictions_gpt)\n",
    "    f1_g = f1_score(actuals, predictions_gpt)\n",
    "    \n",
    "    print('Evaluation Results - Siamese Model:', {\n",
    "        'accuracy': accuracy_s,\n",
    "        'precision': precision_s,\n",
    "        'recall': recall_s,\n",
    "        'f1': f1_s\n",
    "    })\n",
    "    print('Evaluation Results - GPT Model:', {\n",
    "        'accuracy': accuracy_g,\n",
    "        'precision': precision_g,\n",
    "        'recall': recall_g,\n",
    "        'f1': f1_g\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"siamese\": {\"accuracy\": accuracy_s, \"precision\": precision_s, \"recall\": recall_s, \"f1\": f1_s},\n",
    "        \"gpt\": {\"accuracy\": accuracy_g, \"precision\": precision_g, \"recall\": recall_g, \"f1\": f1_g}\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f7cba-4e1b-4dca-9f64-07ba42b0836d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename 00df59d8-dde0-469e-8fb8-792b2ef69778.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\aa61583b-497d-43c1-b998-729a9af42a90_0.png: Distance = [0.14239636], Similar = [ True]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\7a688174-453f-4e22-b068-37ad4cf8c3f9_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\21d5125d-5dae-48f4-a71e-62a9e551a954_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\b2df743e-0f8d-4fe0-8fd9-80500a138c5c_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\2e08fa73-09bd-436c-a57d-d89ee0d950c1_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\5da45665-8c30-4d28-937f-8374235d28ad_1.png: Distance = [0.02462915], Similar = [ True]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\6fdd7802-2bd3-4e23-a49d-92ebb9909195_0.png: Distance = [0.27570882], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\dummy_class\\b6881669-0254-4714-97df-42bcb1c5fd75.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\f3fd26ed-9ca6-4f18-96c6-249f4264c5bc_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\8e7a76ab-764f-40d2-b291-c98ce714d04b_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\883636d3-2f04-4a89-92a5-8e095815263b_0.png: Distance = [0.4108999], Similar = [ True]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\00df59d8-dde0-469e-8fb8-792b2ef69778.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\0ff472dc-e169-4582-bd78-ee1ba34ad1bf_1.png: Distance = [0.], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "API result *** ANOMALOUS ***\n",
      "\n",
      "This appears to be a medical image, possibly an MRI scan or CT scan, showing a cross-sectional view possibly of a head, based on the presence of what might be skull structures. However, this image has a lack of clarity and precision that would be unexpected in a professionally derived medical image. It seems overly processed or stylistically modified which is not typical for standard diagnostic images meant for medical assessment. This could represent processing artifacts or artistic depiction, neither of which would be present in a typical diagnostic imaging scenario.\n",
      "Filename 1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\c708f3ca-86c0-420a-9294-dd3996619941_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\d485542d-5de1-4f75-af25-c0de92513b8e_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\a619f51c-ea42-446a-96ac-8dfde1932677_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\8219f071-0e35-467c-a9e7-ba8f4b5e958f_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\7be10dbf-0923-43ef-8257-48fd80882876_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\c041e1ee-a4ea-43be-aeb9-2826c8db9413_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\ff655528-79b0-40bb-9620-e842a752f01c_0.png: Distance = [0.27789816], Similar = [ True]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\dummy_class\\ff7c739b-e765-409b-a1f9-cc5f2a9b814e.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\cf7d8808-d40a-4596-88f0-a8eb1c2ecca6_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\dummy_class\\fe80f681-0b0d-411e-9eca-2c52dce7b6d4.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\a3b7aec5-d98f-4095-85a1-6f68e8fb5455_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a4fa34b-1f56-4a24-a44a-bf06948e89bb.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\8dcc351b-d91c-4714-b04a-df033e852c36_1.png: Distance = [0.], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "API result *** NORMAL ***\n",
      "Filename 0c50f78b-8270-4e7b-96b3-84223836fe84.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\dummy_class\\44028529-7778-4fa4-910f-60feeddbedfc.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\a7ef1ec1-60b5-4fbc-a4ac-fb1b4242b993_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\89b14bec-9152-4b07-b99f-65339253b67e_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\23e8b54a-64d7-4cb9-974d-cdb14b09808f_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\15072671-0ee6-4e88-9a5e-2a157622443c_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\dummy_class\\6f410042-55e1-44f9-98b8-8d38c544d37d.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\002cbb3d-7e18-47cb-86d6-00e13517fe03_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\d984c230-6095-4cb6-881e-6a3a19484a66_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\779b9d16-0689-46ff-be2c-066af7e3c358_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\dummy_class\\44374976-c8c3-4761-bdb8-03e5ff85bb87.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\e7e98622-ae69-4503-8042-13af4a7c825c_0.png: Distance = [0.07771441], Similar = [ True]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\0c50f78b-8270-4e7b-96b3-84223836fe84.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\8219f071-0e35-467c-a9e7-ba8f4b5e958f_1.png: Distance = [0.], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "API result *** NORMAL ***\n",
      "Filename 2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\d1476a1d-513d-43e4-a63d-ab24189f9d21_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\dummy_class\\f9c0e3f3-aea2-406a-a4fd-115b64e27b0b.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\b3fbf5e3-7e02-4605-a81a-5a21f26740e6_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\3c19d76d-9d6d-46b7-b773-1a0395c40868_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\dummy_class\\ba983c30-7cd9-4adc-a959-41ee298328e5.png: Distance = [0.2809469], Similar = [ True]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\cad1e1d5-a0e4-4c86-bc32-d559d2788ebd_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\8078757d-ea7a-433b-96e8-27097c896b94_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\b2df743e-0f8d-4fe0-8fd9-80500a138c5c_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\c7de3c88-90f9-41a7-95b7-e6827e99d95c_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\66bb7c10-3c5f-4444-bbc0-5b66872591be_0.png: Distance = [0.17118461], Similar = [ True]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\6448e9cd-ab65-442d-999c-0c50ab92a944_1.png: Distance = [0.3635903], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2ad12f46-3ff1-44db-ba39-6e9e685f7b23.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\93da5962-771f-4a10-a999-01b47a65a3dd_0.png: Distance = [0.], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "API result *** NORMAL ***\n",
      "Filename 2c1ec91a-070c-47c3-8c6d-497908239ffe.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\dummy_class\\a31c6ab1-7c7e-48fe-b59f-27b1059908e6.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\613c4ba9-12ac-4c4b-afb1-c0ed3e3d3fe6_1.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\a5224623-a219-41da-a8cc-49a77e86b7dd_0.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\dummy_class\\b0cf7d7f-270e-4b4f-8202-986564dd0546.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\306dd28c-affd-4fb3-86e8-2a4918d5e0d9_0.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\d01c7c4e-f748-4a1f-859d-a60e96d3ac0b_0.png: Distance = [0.31408617], Similar = [ True]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\12c2e265-36e5-4971-bd9b-8b26973ef7e6_1.png: Distance = [0.21088988], Similar = [ True]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\24dd2445-eb9a-49ec-abaa-b695f3657cd3_0.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\97f4a636-650c-43be-a1c2-6f6d805240ef_0.png: Distance = [0.1405221], Similar = [ True]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\b6048bbc-f5b5-4cb8-a59e-577528b5d051_0.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\dummy_class\\e6cbcf4e-a264-4a98-a3a5-aa3103615a03.png: Distance = [0.24138036], Similar = [ True]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\2c1ec91a-070c-47c3-8c6d-497908239ffe.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\b0f3b1b6-664e-40cf-a78c-cb50fdca61f7_1.png: Distance = [0.24138036], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "API result *** NORMAL ***\n",
      "Filename 1c6edbd2-8862-4942-8647-50c57c791181.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\dummy_class\\bd3aceec-b75c-4061-9fde-e276eb58b5d7.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\cb0522a9-f743-401e-b829-1434dcf46b57_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\06e15b16-7f2d-400b-b1d4-6646ae007509_1.png: Distance = [0.19429597], Similar = [ True]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\677b1ea8-876e-441e-b9f0-ba9a6e8a452c_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\b9e05221-3528-4ec0-af67-0b39300a093b_1.png: Distance = [0.01214427], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\4189c278-43b2-4a25-8734-e2aacf6b831f_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\dummy_class\\4d83dbf7-546a-477b-baf1-4ccef0aece3f.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\b0f4ac4f-59bb-4cbf-b885-f5cd515e6029_1.png: Distance = [0.37611464], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\3dfc655c-1b9c-4565-b79f-bbc3aec79220_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\bc548514-7aaa-4f3f-949a-0f21af3bfcaf_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\24d04504-3aef-45d8-b032-63ada4b17565_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1c6edbd2-8862-4942-8647-50c57c791181.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\5c2d7756-a312-42f8-a056-a5c171d95446_1.png: Distance = [0.01210881], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "API result This image appears to be a medical imaging scan, likely an MRI or CT scan, based on the cross-sectional view depicted. The image does not show any obvious textual overlays, annotations, or unusual digital artifacts that would imply alterations by PACS image viewer technology. Thus, this is designated as *** NORMAL ***.\n",
      "Filename 1a93e24f-a340-4fba-8309-9fa71458b861.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\74c4d0e5-6a6a-4ca6-8262-0e8c4f41af18_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\d369fc1f-368a-4fc4-9885-a96848146cf4_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\6ea467bc-104f-415c-b6e6-797c1c533017_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\052379c4-88af-4f3e-8b5a-b704ae679144_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\dummy_class\\25341540-22ee-454e-b65f-924a46b51fa5.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\0a7dcfb9-af6b-4571-99ef-fe87c7ca2fd2_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\1ca41cda-dbf8-45c0-a57c-6574ac0853a1_1.png: Distance = [0.06463797], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\814d5910-8f40-4bd9-ab5b-90b8e985f458_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\dummy_class\\76b2d190-2c11-41de-8930-9989a491c2fd.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\dummy_class\\9327107f-6e24-4534-9dc7-e5660611479e.png: Distance = [0.41158298], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\dummy_class\\56a5172b-9c6d-4d9f-88ac-1f64b8b704a8.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\1a93e24f-a340-4fba-8309-9fa71458b861.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\2d497f55-e0fd-4863-b6f5-6a7dbfd989d2_0.png: Distance = [0.38602594], Similar = [ True]\n",
      "Total votes for 'Similar': [12]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n",
      "Description received.\n",
      "API result *** NORMAL ***\n",
      "Filename fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png\n",
      "Image loaded and processed, predicting...\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\17ef91d2-ecd8-4866-8012-f394b9825a04_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\dummy_class\\01a3adf0-d14b-4be1-adeb-4fa2bd27142d.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\b91a7683-8714-4189-b981-047338808fc2_0.png: Distance = [0.00155569], Similar = [ True]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\47f91cee-0f1d-4309-838c-52e3876b266a_0.png: Distance = [0.6734653], Similar = [False]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\6100a750-d5eb-4d13-ba56-8e98c8d52f18_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\843f76f3-0cb6-4501-ab7b-a67455b347d9_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\052379c4-88af-4f3e-8b5a-b704ae679144_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\2351fd57-a3eb-4457-b22c-88edf0371e23_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\df13097c-cf2f-4866-82b9-3fb586630abe_1.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\329d2720-9ce5-44a7-a4dc-54fca96360ca_0.png: Distance = [0.], Similar = [ True]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\zoomed\\randomized_wl\\c790c80a-c245-44ee-a5f1-c06666e9b951_1.png: Distance = [0.63360864], Similar = [False]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Comparing D:\\model_comparison_test\\valid\\fa32afd7-ab3d-45e2-a9bb-bd6dc1073cda.png with D:\\training_images\\test\\valid\\randomized_wl\\cropped\\114a6449-d13f-4e26-bf5e-bd442774aa5d_0.png: Distance = [0.], Similar = [ True]\n",
      "Total votes for 'Similar': [10]/12. Final verdict: Normal\n",
      "Siamese result Normal\n",
      "Loading image from path for description...\n",
      "Encoding image for API request...\n",
      "Sending image to API...\n"
     ]
    }
   ],
   "source": [
    "# Example call\n",
    "base_folder = r'D:\\model_comparison_test'\n",
    "sample_size = 40\n",
    "try:\n",
    "    results = evaluate_methods_simplified(base_folder, sample_size, jury_size, role, image_description_directive)\n",
    "    print(\"Evaluation Results:\", results)\n",
    "except Exception as e:\n",
    "    print(\"Error during evaluation:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f20f82-139c-432a-9e6d-557674431f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedc117-f248-46ff-b365-bf0538982ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
